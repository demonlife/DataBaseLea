* 基本术语
** 文档
   是mongodb的核心概念, 多个键及其关联的值有序地放置在一起
   1. 文档中的键值对是有序的(通常文档中的键的顺序不重要)
   2. 文档中的值可以不仅仅是字符串, 还可以是其他几种数据类型
   3. 文档的键是字符串, 除少数例外情况, 键可以是任意UTF-8字符
   4. 键不能含有\0(空字符), 该字符用来表示键的结尾
   5. ./$有特别的意义, 特定环境下才能使用
   6. 以_开头的键是保留的, 但不是严格要求的
   7. mongodb的键区分大小写, 值是区分类型的
   8. 文档不能有重复的键
** 集合
   集合是无模式的
   1. 集合名不能是空字符串
   2. 集合名不能含有\0字符
   3. 集合名不能以system. 开头
   4. 用户创建的集合名字不能含有保留字符$
   5. 很多mongodb工具都包含子集合
   6. GridFS是一种存储大文件的协议
   7. MongoDB的web控制台通过子集合的方式将数据组织在DBTOP部分
** 数据库
   多个集合可以组成数据库
   1. 数据库名不能是空字符
   2. 数据库名不得含有空格.$/\和\0
   3. 应全部小写
   4. 最多64字节
   5. 数据库名最终会变成文件系统里的文件
   6. 有些数据库名是保留的, 如:
      admin: 这是"root"数据库, 将用户添加到该数据库, 则该用户自动继承所有数据库的权限
      local: 该数据库永远不会被复制, 可用来存储限于本地单台服务器的任意集合
      config: 当mongodb用于分片设置时, 该数据库在内部使用, 用于保存分片的相关信息
** 启动
   ./mongod 默认的数据目录是/data/db, 使用27017端口, http服务器的端口是28017
** 基本操作
   1. 创建
      post = {'title': 'My Blog Post', 'content': 'here's my blog post.',
          'data': new Date()}
      db.blog.insert(post) #=> 向blog集合中插入数据post
   2. 查看
      db.blog.find()
   3. 更新
      使用update来更新, update接受至少两个参数, 第一个是要更新文档的限定条件, 第二个是新的文档
   4. 删除
      remove从数据库中永久性的删除文档. 在不使用参数进行调用的情况下, 会删除一个集合内的所有文档
** mongodb shell的使用
   help: 获取帮助
   有个了解函数的技巧: 在输入的时候不要输入括号, 这样就会显示该函数的javascript源代码
   当有属性与目标集合同名时, 可以使用getCollection函数
   db.getCollection("version")
   var collections = ["posts", "comments", "authors"]
   for (i in collections) {
       // i = 0, 1, 2
   }
   
* 基本操作
  大于4MB的文档是不能存入数据库的, 在shell中运行Object.bsonsize(doc)可以查看改文档的大小
  MongoDB在插入数据时并不执行代码, 所以没有注入式攻击的可能
  db.blog.remove(): 删除blog集合的所有文档, 但不会删除集合本身, 原有的索引也会保留, 删除数据后不能撤销
  如果需要删除索引, 则可以使用db.drop_collection("collectionname")
** 更新文档
   更新是原子操作, 若是两个更新同时发生, 先到达服务器的先执行, 互相有冲突的更新可以火速传递, 不会互相干扰,
   最后更新的会取得"胜利"
   使用原子的更新修改器, 可以让更新极为高效, 例如:
   db.analytics.update({"url":"www.example.com"}, {"$inc": {"pageview":1}})
   使用修改器时, "_id"的值不能改变, 但是整个文档替换时是可以改变"_id"的, 其他键值包括唯一索引都是可以更改的
*** $set修改器
    $set指定一个键的值, 如果键不存在就创建,有则设置为指定的值, $set甚至可以修改键的数据类型, 也可以修改内嵌文档
    $unset将键完全删除
    示例:
    db.blog.update({"title": "test"}, {"$set": {"createat": new Date()}});
    db.blog.update({"title":"test"}, {"$unset":{"createat": new Date()}});
*** $inc修改器
    $inc是用来增加已有键的值, 或者在键不存在时创建一个键.
    db.games.update({"game":"pinball"}, {"$inc":{"score":50}}) #给score加50(score存在)否则设置score=50
    $inc只能用于数字(整数, 长整数,双精度浮点数), 不能用于字符串、数组或其他非数字类型的值
*** 数组修改器
    若指定的键存在, $push会向已有的数组末尾加入一个元素, 要是没有就会创建一个新的数组
    db.blog.posts.update({"title":"A blog post"}, {$push: {"comment": {"name":"wnb", "content":"good"}}})
    如果一个值不在数组里就将其加进去, 可以在查询文档中用$ne来实现, 例如:
    db.papers.update({"authors": {"$ne":"Richie"}}, {$push:{"authors":"Richie"}});
    也可以使用$addToSet完成同样的事情, 有些情况使用$ne是不行的, 更适合使用$addToSet
    $addToSet在添加值时, 可以避免重复
    $addToSet与$each组合起来可以添加多个不同的值,例如:
    db.users.update({"name":"wnb"}, {$addToSet: {"email":{$each: ["wnb@gmail.com", "wnb@163.com"]}}});
    从数组中删除元素的方法, 可以用$pop, 该修改器可以从数组的一端删除元素,{$pop: {key:1}}从数组末尾删除一个元素
    {$pop: {key: -1}}从头部删除一个元素, $pull基于特定条件来删除元素,$pull,会将所有所有匹配的部分删掉,例如:
    db.lists.update({}, {$pull:{"todo":"ok"}})
*** 数组定位修改器
    数组有多个值, 只想对其中的一部分进行操作, 有两种方法操作数组中的值, 通过位置或者定位操作符$,
    数组都是以0开头的, 可以将下标直接作为键来选择
    db.blog.update({"post":"post"}, {"$inc":{"comments.0.votes":1}})
    db.blog.update({"comments.author":"John"}, {"$set":{"comments.$.author":"Jim"}})
    定位符只会更新第一个匹配的元素, 如果John不止有一个评论, 那么只更新第一条评论中的名字
*** upsert
    如果没有符合更新条件的文档, 就会以这个条件和更新文档为基础创建一个新的文档
    db.analytics.update({"url":"/blog"}, {"$inc":{"visits":1}}, true), #update的第三个参数表示
    这个是一个upsert操作
*** save
    save是一个shell函数, 可以在文档不存在时插入, 存在时更新, 如果该文档含有"_id"键, save会调用
    upsert. 否则会调用插入.
*** 更新多个文档
    要使得所有匹配到的文档都得到更新, 可以设置update的第4个参数为True, 服务器可能默认会更新所有匹配
    的文档, 只有第4个参数为false才会只更新一个, 所以建议每次都显示表明要不要做多文档更新
    想要知道多文档更新到底更新了多少文档, 可以运行getLastError命令或getLastOpStatus, 键n的值就是要的
    数值
    db.runCommand({getLastError:1});
*** 返回已更新的文档
    findAndModify的调用方式和普通的更新略有不同, 还有点慢, 原因是要等待数据库的响应.
    db.runCommand({"findAndModify":"processes",
        "query":{"status":"READY"},
        "sort":{"priority":-1},
        "update":{"$set":{"status":"RUNNING"}}})
    其中processes是集合名, -1表示倒序排列
    findAndModify既有update键也有remove键, remove键表示将匹配道德文档从集合中删除, new键表示
    返回的是更新前还是更新后的键, 默认为更新前的键
    db.runCommand({"findAndModify":"processes",
        "query":{"status":"READY"},
        "sort":{"priority":-1},
        "remove":true},
        "new": true)
    update/remove必须有一个, 也只能有一个, 要是匹配不到文档, 该命令返回null, 该命令一次只能处理
    一个文档, 不能执行upsert操作, 只能更新已有文档
*** 捕获"常规"错误
    安全操作可以在开发阶段用来调试数据库的奇怪行为
* 查询 
** 指定查询返回的键
   通过find, findOne的第二个参数来指定想要的键, _id:总是被返回
   db.users.find({}, {"username":1, "email":1}) #显示username, email
   db.users.find({}, {"username":0, "_id":0} #其他键都显示, 只有username, _id不显示
   数据库所关心的查询文档的值必须是常量, 即不能引用文档中其他键的值, 在程序中可以使用变量
** 查询条件
   "$lt" "$lte" "$gt" "$gte" "$ne" 对应<, <=, >, >=, !=
   db.users.find({"age":{"$gte":18, "$lte":30}})
   $ne可以用于所有数据类型
   $in: 查询一个键的多个值, 可以指定不同类型的条件和值
   $nin: 与$in相对
   $or: 接受一个包含所有可能条件的数组作为参数
   db.raffle.find({"$or":[{"ticket_no": {"$in":[725, 542, 390]}}, {"winner":true}]})
   使用$or时, 第一个条件尽可能地匹配更多的文档, 这样才最为有效
   $mod会将查询的值除以第一个给定值, 若余数等于第二个给定值则返回该结果
   db.users.find({"id_num": {"$mod":[5,1]}})
   db.users.find({"id_num": {$not:{"$mod":[5,1]}}})
   $not与正则表达式联合使用的时候极为有用
   通过以上查询的观测, 发现条件语句是内层文档的键, 而修改器则是外层文档的键
   一个键可以有多个条件, 但一个键不能对应多个更新修改器
*** null
    null能匹配自身, 而且也匹配不存在的, 即不存在某个键的文档
    如果仅仅想匹配键值为null的文档, 还要通过$exists条件判断键值是否已经存在
    db.c.find({"z":{"$in":[null], "$exists": true}})
*** 正则表达式
    db.users.find({"name":/joe/i})
    mongodb使用perl兼容的正则表达式库来匹配正则表达式, pcre支持的正则表达式语法都能被mongodb所接受
    mongodb可以为前缀型正则表达式创建索引, 正则表达式也可以匹配自身
*** 查询数组
    数组可以理解为每一个元素都是整个键的值.
    db.food.insert({"fruit":["apple","banana", "peach"]})
    db.food.find({"fruit":"banana"}) #可以查到到上述的数据
    db.food.find({"fruit":{$all:["apple", "banana"]}}) #找到既有apple还有bananan的文档
    查找数组指定位置的元素, db.food.find({"fruit.2":"peach"})
    $size: 可以查询指定长度的数组, $size不能与其他查询子句组合
    $slice: db.blog.posts.findOne(criteria, {"comments": {"$slice": 10}}) # 返回前10条评论
    db.blog.posts.findOne(criteria, {"comments":{"$slice":-10}}) #返回后10条
    db.blog.posts.findOne(criteria, {"comments":{$slice: [23, 10]}}) #跳过前23个元素, 返回10个
    查找内嵌文档:
    db.people.find({"name":{"first":"Joe", "last":"Schmoe"}}) #该查询是明确匹配, 而且还是顺序相关的
    db.people.find({"name.first":"Joe", "name.last":"Schmoe"}) #则是查询只要name.fisrt=x&&name.last=x的数据

    #查询joe写的评分大于等于5的评论, $elemMatch将限定条件进行分组, 仅当需要对一个内嵌文档的多个键
    #操作时才会用到
    db.blog.find({"comments":{"$elemMatch":{"author":"joe", {"score":{"$gte":5}}}}})
*** $where        
    db.foo.insert({"apple":1, "banana":6, "peach":3})
    db.foo.insert({"apple":8, "spinach":4, "watermelon":4})
    db.foo.find({"$where": functioin() {
        for (var current in this) {
            for (var other in this) {
                if (current != other && this[current] == this[other]) {
                    return true;
                }
            }
        }
        return false;
    }});
    如果函数返回true, 文档就作为结果的一部分被返回
    $where的值也可以用一个字符串来指定
    db.foo.find({"$where":"this.x + this.y == 10"})
    不是必要时, 一定要避免使用$where查询, 因为在速度上要比常规查询慢很多
*** limit, skip, sort
    db.c.find().limit(3) #3指定的是上限而非下线
    db.c.find().skip(3) #跳过前3个
    db.c.find().sort({username:1,age:-1}) #按username升序排列, age降序排列
    略过过多的结果会导致性能问题
    对混合类型的排序, 其排序结果是预先定义好的, 从小到大, 其顺序如下:
    最小值, null, 数字, 字符串, 对象/文档, 数组, 二进制数据, 对象ID, 布尔型, 日期型, 时间戳,
    正则表达式, 最大值
**** 不用skip对结果分页    
     首先获取第一页数据, 然后将第一页中的某个数据作为作为下一页的查询条件
* 索引
  索引就是用来加速查询的.
  db.people.ensureIndex({"username":1}) #对username建立索引, 对于同一个集合, 同样的索引只需要
  创建一次, 1/-1表示索引创建的方向, 1:升序排列, -1:降序排列, 若索引只有一个键,
  db.foo.ensureIndex({"a":1, "b":2}, {"name": "alphabet"}) #创建索引时命名
  db.foo.ensureIndex({"username":1},{"background":true}) #可以使这个过程在后台完成
  如果不包括background选项, 数据库会阻塞建立索引期间的所有请求
  可以使用getLastError来检查索引是否成功创建了或失败的原因
  则方向无关紧要, 若是有多个键, 就得考虑索引的方向问题
  实践表明: 一定要创建查询中使用到的所有键的索引
  只有使用索引前部的查询才能使用该索引
  创建索引时应该考虑的问题:
  1. 会做什么样的查询, 其中那些键需要索引
  2. 每个键的索引方向是怎样的
  3. 如何应对扩展, 有没有种不同的键排列可以使常用数据更多的保留在内存中
  db.blog.ensuerIndex({"comments.date":1}) #为内嵌的文档建立索引
** 为排序创建索引
   一旦集合达到不能在内存中排序, Mongodb就会报错
** 唯一索引
   db.people.ensureIndex({"username":1}, {"unique":true})
   db.people.ensureIndex({"username":1}, {"unique":true, "dropDups":true}J) #删除重复的值但保留
   发现的第一个文档
** explain/hint
   帮组获取查询方面的有用信息
   db.foo.find().explain() #返回查询使用的索引情况(如果有的话), 耗时以及文档数的统计信息
   db.system.indexes.find({"ns":"test.foo", "name":"age_1"}) #查询test.foo集合的索引名为age_1的索引信息
   db.c.find({"age":14, "username":/.*/}).hint({"username":1, "age":1}) #强制使用某个索引
   mongodb的查询优化器非常智能, 初次做某个查询时, 查询优化器会同时尝试各种查询方案, 最先被完成的被
   确定使用, 查询优化器定期重试其他方案, 以防因为添加新数据后, 之前的方案不再是最优的了
   索引的元信息存储在每个数据库的system.indexes集合中, 这是一个保留集合, 不能对其插入或者删除,
   操作只能通过ensureIndex或dropIndex
   system.namespaces集合页含有索引的名字.查看该集合会发现每个集合至少有两个文档与之对应,
   一个对应集合本身, 一个对应集合包含的索引. 如: {"name":"test.foo"}, {"name":"test.foo.$_id_"}
   db.runCommand({"dropIndexes":"foo", "index":"alphabet"})
   db.runCommand({"dropIndexes":"foo", "index":"*"}) #删除所有索引
** 地理空间索引
   db.map.ensureIndex({"gps":"2d"})
   gps键的值必须是某种形式的一对值, 一个包含两个元素的数组或是包含两个键的内嵌文档
   {"gps":[0, 100]}, {"gps":{"x":-30, "y":30}}都是有效的键值对
   默认情况下, 地理空间索引值假设的范围是-180～180, 要是想用其他值, 可以指定选项来指定值
   db.star.trek.ensureIndex({"light-years":"2d"}, {"min":-1000, "max": 1000})
   db.map.find({"gps":{"$near":[40, -73]}}) #默认返回100个文档
   db.map.find({"gps":{"$near":[40, -73]}}).limit(10) #返回10个文档
   db.runCommand({geoNear: "map", near:[40, -73], num:10}), geoNear会返回每个文档到查询店的距离
* 聚合
** count
   返回集合中的文档数量
   db.foo.count()
   db.foo.count({"x":1}) # 增加查询条件会使得count变慢
** distinct
   用来找出给定键的所有不同的值, 使用时必须指定集合和键
   db.runCommand({"distinct":"people", "key":"age"})
** group   
   根据选定分组所依据的键, 而后mongodb就会将集合依据选定键值的不同分成若干组.然后可以通过聚合每一组
   内的文档, 产生一个结果文档
   db.runCommand({"group":{
       "ns": "stocks",
       "key": "day",
       "initial": {"time": 0},
       "$reduce": function(doc, prev) {
           if (doc.time > prev.time) {
               prev.price = doc.price;
               prev.time = doc.time;
           }
       },
       "condition": {"day":{"$gt":"2010/09/30", "$exists":true}}
   }})
   "inital": {"time":0} #每一组reduce函数调用的初始时间, 会作为初始文档传递给后续过程
   "condition": xx #迭代的结束条件, $exists # 排除day不存在的数据
*** 使用完成器
    用于精简从数据库传到用户的数据, 可以在group中添加finalize键
    db.runCommand({"group": {
        "ns": "posts",
        "key": {"tags":true},
        "initial": {"tags": {}},
        "$reduce": functioni(doc, prev) {
            for (i in doc.tags) {
                if (doc.tags[i] in prev.tags) {
                    prev.tags[doc.tags[i]] ++;
                } else {
                    prev.tags[doc.tags[i]] = 1;
                }
            },
        "finalize": function(prev) {
            var mostPopular = 0;
            for (i in prev.tags) {
                if (prev.tags[i] > mostPopular) {
                    prev.tag = i;
                    mostPopular = prev.tags[i];
                }
            }
            delete prev.tags;
        }
    }}})
*** 将函数作为键使用    
    db.posts.group({"ns":"posts",
        "$keyf": function(x) { return x.category.toLowerCase(); },
        "initalizer": ... })
** MapReduce        
   MapReduce很慢, 绝对不要在实时任务中, 要作为后台任务来运行MapReduce
   每个传递给map函数的文档都要事先反序列化, 从BSON转换为javascript对象, 事先增加一层过滤
   会极大的提高速度.

   #map, reduce是自己定义好的函数
   db.runCommand({"mapreduce":"analytics", "map":map, "reduce":reduce, "limit":100, "sort":{"date":-1}})

   db.runCommand({"mapreduce":"webpages", "map":map, "reduce":reduce,
       "scope": {now: new Date()}})
   这样, 在map函数中就能计算1/(now - this.date)了
   如果想看mapreduce的运行过程, 可以用"verbose":true
* 进阶
** 固定集合
   固定集合很像一个环形队列
   对固定集合插入速度极快, 按查找顺序输出的查询速度极快
   db.createCollection("my_collection", {capped:true, size:10000, max:100})
   #创建一个固定集合my_collection, 大小是10000字节,max指定文档数量的上限
   db.runCommand({convertToCapped:"test", size:10000}) #将已有集合转换为固定集合
** 自然排序
   固定集合有种特殊的排序方式, 叫自然排序, 就是文档在磁盘上的顺序
   {$natural:1}表示与默认顺序相同, 非固定集合不能保证文档按照特定顺序存储
   {$natural:-1}与默认顺序相反
** 尾部游标   
   这类游标不会在没有结果后销毁, 一旦有新文档添加到集合里去就会被取回并输出.只能用于固定集合上
   Mongoshell不支持尾部游标
** GridFS
   存储大二进制文件的机制.GridFS在同一个目录下放置大量的文件没有任何问题, GridFS不产生磁盘碎片
   Mongodb分配数据文件空间时以2GB为一块
*** 使用
    mongofiles put file #存入文件
    mongofiles get file #下载文件
    mongofiles list #列出文件
    mongofiles search file #用来按文件名查找GridFS中的文件
    mongofiles delete file #删除文件
*** 内部原理        
    GridFS是一个建立在普通mongodb文档基础上的轻量级文件存储规范.
    基本思想就是可以将大文件分成很多块, 每块作为一个单独的文档存储
    除了存储文件本身的块, 还有一个单独的文档用来存储分块的信息和文件元数据
    GridFS的块有个单独的集合, 默认时, 块将使用fs.chunks集合.
    文件的元数据放在另一个集合中, 默认是fs.files
*** 服务器端脚本
    在服务器端可以通过db.eval函数来执行javascript脚本, 也可以将js脚本保存在数据库中
    db.eval可以用来模拟多文档事务, db.veal锁住数据库, 然后执行js, 再解锁
    db.eval("return 1;")
    db.eval("function() { return 1;}")
    只有在传递参数时, 才必须要封装为一个函数

    v2.6.0返回x + y + z的值
    db.eval("function(x, y, z) {return x + y + z;}", x, y, z)
    db.eval("print('hello');") #会将数据打印至数据库日志中
    调试db.eval的方法是, 将调试信息写进数据库日志中, 可以通过print函数来完成
*** 存储javascript
    每个mongodb的数据库中都有特殊的集合, 即system.js, 用来存放javascript变量.
    这些变量可以在任何mongodb的javascript上下文中调用, 包括$where子句, db.eval调用, mapreduce作业
    db.system.js.insert({"_id":"x", "value":1}) #存放变量
    db.system.js.insert({"_id":"log", "value":
    function(msg, level) {
        var levels = ["DEBUG", "WARN", "ERROR", "FATAL"];
        level = level ? level : 0;
        var now = new Date();
        print (now + " " + levels[level] + msg);
    }});
    db.eval("x=1; log('x is ' + x); x = 2; log('x is greater than 1', 1);")
    使用存储的js缺点就是代码会与常规的源代码控制脱离, 会搅乱客户端发送来的js
    当js代码很长又要频繁使用时, 可以使用存储的js
    执行javascript代码, 需要考虑到类似于关系型数据库的注入攻击
** 数据库引用
   DBRef就像url, 唯一确定一个到文档的引用
   DBRef有一些必选键, 例如: {"$ref":collection, "$id":id_value}
   DBRef指向一个集合, 还有一个id_value用来在集合里根据"_id"确定唯一的文档. 如果想引用另一个数据库
   中的文档, DBRef有个可选键"$db", DBRef中键的顺序不能改变, 第一个必须是"$ref", 接着是"$id",
   然后是可选的$db.
   例子:
   user表的数据如下:
   db.user.insert({"_id":"mike", "display_name":"Mike D"});
   db.user.insert({"_id":"kristina", "display_name":"Kristina C"});
   notes表的数据如下:
   db.notes.insert({"_id":5, "author":"mike", "text":"Mongodb is fun!"})
   db.notes.insert({"_id":20, "author":"kristina", "text":"... adn dbrefs are easy, too", "references":[{"$ref":"users", "$id":"mike"}, {"$ref":"notes", "$id": 5}]})
   查询操作:
   var note = db.notes.findOne({"_id": 20})
   note.references.forEach(function(ref) {
       printjson(db[ref.$ref].findOne({"_id":ref.$id}));
   });
* 管理
** 启动
   可以使用mongod --help查看帮助文档
   --dbpath: 指定数据目录, 默认是/data/db, windows下是C:\data\db, 每个mongod进程都需要独立的数据库目录
   mongod启动时, 会在数据目录中创建ongod.lock文件, 该文件用于防止其他mongod进程使用改数据目录.如果使用
   同一个数据目录启动另一个mongodb服务器, 则会报错: unable to acquire lock for lockfilepath: /data/db/mongod.lock
   --port: 指定服务器监听的端口号, 默认端口是27017, 如果运行多个mongod进程, 则要给每个指定不同的端口号
   --fork: 以守护进程的方式运行mongodb
   --logpath: 指定日志输出路径, 而不是输出到命令行, 如果想保留原来的日志, 还需使用--logappend
   --config: 加载指定配置文件, 加载命令行未指定的各种选项
   例子:
   mongod --port 5586 --fork --logpath mongodb.log --dbpath xxpath
   第一次运行mongod程序时, 最好看看日志信息.在每次安装, 升级, 宕机后应该再一次确认日志信息
   指定配置文件可以使用-f或者--config选项, 例子:
   #start mongodb as a daemon on prot 5586, 注释
   port = 5586
   fork = true # daemonize it
   logpath = mongodb.log
   如果需要使用web rest接口，需要加上参数--rest
** 关闭mongodb
   kill -2 pid 或者 kill pid
   千万不要向运行中得mongodb发送SIGKILL,kill -9, 这会导致数据库直接关闭, 会让数据库文件损坏.
   如果真的损坏了, 一定要在启动备份前修复数据库.
   另一种稳妥的方式是在mongognshell中使用shutdown命令, 需要在admin数据库下使用,
   db.shutdownServer()
   获取运行中得Mongodb服务器统计信息,最基本工具就是serverStatus命令
   部分信息解释:
   globalLock: 全局写入锁占用了服务器多少时间以微妙记, mem:包含服务器内存映射了多少数据, 服务器进程的
   虚拟内存和常驻内存的占用情况单位MB, indexCounters: B树在磁盘检索和内存检索的次数, 如果该比值开始上升
   就应该考虑添加内存了. backgroundFlushing: 后台做了多少次fsync以及用了多少时间. opcounters: 包含了
   每种主要操作的次数, assert: 统计了断言的次数.
   serverStatus结果中得所有计数都是在服务器启动时开始计算的, 如果过大就会复位, 所有计数器都复位,
   assert中得rollovers值会增加.
   mongostat: 输出一些serverStatus提供的重要信息.
** 安全和认证
   mongodb支持对单个连接的认证, 即便这个认证的权限模式很简陋.
   如果开启了安全性检查, 则只有数据库认证用户才能执行读写操作.在认证的上文中, mongodb会将普通数据作为admin
   数据库处理, admin数据库中得用户被视为超级用户. 在认证之后, 管理员可以读写所有的数据库, 执行特定的管理
   命令.
   例子:
   use admin
   db.addUser("root", "toor")
   use test
   db.addUser("test_user", "test")
   db.addUser("read_only", "test", true)
   添加了管理员账号, 在test数据库下添加了两个普通账号,创建只读用户只要将addUser的第3个参数设为true就可以了.
   调用addUser必须有相应数据库的写权限.
   addUser不仅能添加用户, 还能修改用户口令或者设置只读状态.
   mongod --auth --dbpath ... #开启安全检查
   show dbs #列举所有数据库
*** 认证的工作原理
    数据库的用户账号以文档的形式存储在system.users集合里,
    db.system.users.remove({"user": "test_user"}) #删除用户
    即便启用了认证, mongodb传输协议也是不加密的, 如果需要加密可以用ssh隧道或类似的技术做客户端与服务器间的加密
    mongod --bindip localhost #只能从本机应用服务器访问.
    --nohttpinter-face : 关闭http管理接口
    --noscripting: 完全禁止服务器端javascript的执行.
** 备份
   要想备份mongodb, 只要简单创建数据目录中得所有文件的副本就可以了, 但是采用这种方式备份, 需要mongodb停机
*** mongodump/mongorestore
    mongodump将所有查到的文档写入磁盘,即便正在处理其他请求或是执行写入也没有问题.
    mongodump使用普通的查询机制, 所以产生的备份不一定是服务器数据的实时快照.并且备份时的查询会对其他
    客户端的性能产生不利影响.
    mongodump --help #查看帮助
    mongorestore获取mongodump的输出结果, 并将备份的数据插入到运行中的mongodb中.
    mongodump -d test -o backup # 备份test数据库
    mongorestore -d foo --drop backup/test
    --drop: 代表恢复前删除集合, 否则数据就会与现有集合数据合并, 可能会覆盖一些文档.
*** fsync和锁
    fsync命令能够在mongodb运行时复制数据目录还不会损坏数据.
    fsync命令会强制服务器将所有缓冲区写入磁盘, 还可以选择上锁阻止对数据库的进一步写入, 直到释放为止.
    use admin
    db.runCommand({"fsync":1, "lock": 1});
    备份好了, 就需要解锁:
    db.$cmd.sys.unlock.findOne();
    db.currentOp(); #运行currentOp是为了确保已经解锁.
    在从服务器上的备份是mongodb推荐的备份方式.
** 修复数据
   最简单的方式是加上--repair; mongodb --repair.修复数据库的实际过程是: 将所有的文档导出然后导入,
   忽略那些无效的数据. 完成后, 会重新建立索引.
   修复运行中得服务器上的数据库:
   use test
   db.repairDatabase()
   
* 复制
  强烈建议在生产环境中使用mongodb的复制功能
** 主从复制
   1. 首先给主节点建立数据目录, 并绑定端口
      mkdir -p /dbs/master
      mongod --dbpath /dbs/master --port xx --master
   2. 设置从节点, 要选择不同端口和数据目录
      mkdir -p /dbs/slave
      mongod --dbpath /dbs/slave --port xx --slave --source localhost:xx #在本地建立主从
   不超过12个从节点的集群就可以运转良好
*** 主从复制的选项
    --only: 在从节点上指定只复制某个特定数据库, 默认复制所有数据库
    --slavedelay: 用在从节点上, 当应用主节点的操作时增加延时,单位是秒, 这样就能轻松设置延时从节点了.
    --fastsync: 以主节点的数据快照为基础启动从节点
    --autoresync: 自动同步
    --oplogSize: 主节点oplogSize的大小, MB
*** 添加及删除源
    启动从节点时, 可以不添加源, 可以随后向sources集合添加主节点信息:
    use local
    db.sources.insert({"host":"localhost:27107"});
    改变从节点的配置:
    db.sources.insert({"host":"xxx"})
    db.sources.remove({"host":"xxx"})
    如果切换的两个主节点有相同的集合, mongodb会尝试合并, 但不能保证正确合并.
** 副本集
   自动故障恢复功能的主从集群. 主从集群和副本集群最明显的区别是副本集没有固定的"主节点", 整个集群会选出
   一个"主节点", 当其不能工作时, 则变更到其他节点.副本集总会有一个活跃节点和一个多个备份节点.
*** 初始化副本
    设置副本时,不能用localhost地址作为成员, 需要找到机器的主机名.
    为每一个服务器创建数据目录, 选择端口
    mkdir -p /dbs/node1 /dbs/node2
    启动之前需要给副本集起个名字, 名字是为了易于与别的副本集区分
    mongod --dbpath dbpath --port xx --replSet name/hostname:port 
    #name为副本的名字, hostname为系统的主机名, port为其他副本的端口号
    例如:
    mongod --dbpath /tmp/dbs/node1 --port 10001 --replSet blort/demon:10002
    mongod --dbpath /tmp/dbs/node2 --port 10002 --replSet blort/demon:10001
    添加第三台时, 下面两种方式都可以:
    mongod --dbpath /tmp/dbs/node3 --port 10003 --replSet blort/demon:10001
    或者
    mongod --dbpath /tmp/dbs/node3 --port 10003 --replSet blort/demon:10001, demon:10002
    副本集具有自检测功能, 在其中指定单台服务器后, mongodb会自动搜索并连接其余的节点,
    启动了几台服务器后, 日志会提示副本集没有进行初始化, 需要在shell中初始化副本集
    在shell中连接其中任何一个服务器, 执行初始化命令, 初始化命令只能执行一次
    use admin
    db.runCommand({"replSetInitiate":{"_id":"blort", "members":[{
        "_id":1, "host":"demon:10001"}, {"_id":2, "host":"demon:10002"}]}})
    _id: 副本集的名字
    members: 副本集中的服务器列表, 过后还能添加, 每个服务器至少有两个键, _id服务器唯一ID, host:服务器主机
    配置会在服务器间传递
*** 副本集中的节点
    副本集中节点的分类:
    standard: 常规节点, 存储一份完整的数据副本, 参与选举投票, 有可能成为活跃节点
    passive: 存储完整的数据副本, 参与投票, 不能成为活跃节点
    arbiter: 仲裁者只参与投票, 不接受复制的数据, 不能成为活跃节点
    在节点配置中修改priority键, 配置成标准节点或是被动节点:
    use admin
    members.push({"_id": 3, "host":"demon:10003", "priority": 40}) #默认优先级为1, 可以是0-1000(含)
    members.push({"_id":4, "host":"demon:10004","arbiterOnly":true}) #指定为仲裁者
    备份节点会从活跃节点中抽取oplog, 并执行操作.
    如果活跃节点坏了, 其余节点会选一个新的活跃节点, 选举过程可以由任何非活跃节点发起.新的活跃节点将是优先级
    最高的节点, 优先级相同则数据较新的成为活跃节点

    活跃节点使用心跳来跟踪集群中有多少节点对其可见.如果不够半数, 活跃节点会自动降为备份节点.
    不论活跃节点何时变化, 新活跃节点的数据就被假定为最新的数据, 其他节点的操作都会回滚.
*** 读扩展
    设置主从复制, 连接从服务器处理请求, 唯一的技巧就是有个特殊的查询选项, 告诉从服务器是否可以处理请求,
    默认是不处理, 该选项叫做slaveOkay, 所有mongodb驱动程序都提供了一种机制来设置它.
** 工作原理
   主节点负责处理客户端请求, 其他从节点负责映射主节点的数据.
   从节点定期轮循主节点获取这些操作, 然后对自己的数据副本执行这些操作.
   主节点的操作记录称为oplog(operation log), oplog存在一个特殊的数据库中, 叫做local.
   oplog就在其中的oplog.$main集合里.
   oplog中的每个文档都代表主节点上执行的一个操作. 文档包含的键如下:
   ts: 操作的时间戳.由4字节的时间戳和4字节的递增计数器构成
   op: 操作类型
   o: 指定要做执行操作的文档
   oplog只记录改变数据库状态的操作.
*** 复制状态和本地数据库   
    本地数据库就是local, 其内容不会被复制
    主节点上的复制状态还包括从节点的列表, 从节点在连接主节点时会执行handshake命令进行握手
    这个列表存放在slaves集合中
    在主数据库中执行: db.slaves.find()
    在从数据库中执行: db.sources.find()
*** 阻塞复制    
    db.runcommand({getLastError:1, w: N})
    如果没有N,或者小于2, 命令会立刻返回, 如果N等于2, 主节点要等到至少一个从节点复制了上个
    操作才会响应命令.
    主节点使用local.slaves中存放的"syncedTo"信息跟踪从节点的更新情况.
** 诊断
   连接到主节点, db.printReplicationiInfo();
   连接到从节点, db.printSlaveReplicationInfo();
*** 复制的认证
    本地数据库的用户能够读写整个服务器
    从节点在连接主节点时, 会用存储在local.system.usres中的用户进行认证.
    最先尝试repl用户, 若没有, 则用local.system.users中的第一个可用用户
    use local
    db.addUser("repl", password)
* 分片
  在没有分片时, 客户端连接mongod进程, 分片时客户端会连接mongos进程
** 片键
   设置分片时, 需要从集合里选一个键, 用该键的值作为数据拆分的依据.该键称为片键
* 补充
  Mongodb的版本号, 偶数的版本号是稳定版, 奇数的是开发版, 1.6.x就是稳定版
  当分支版本进入x.y.5的时候, 就非常接近可用于生产的水平了.
  mongo localhost:27017/admin 连接admin数据库, 而不是默认的test数据库
  mongo --nodb # 不连接数据库, 只是想试试javascript
* Mongo 工具
** mongo shell 结果优化显示
   mongo hacker：https://github.com/TylerBrock/mongo-hacker
